{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decoder LLM with KV Cache: Prefill and Decode Demonstration\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. How a simple decoder LLM works\n",
        "2. The prefill phase (processing initial prompt tokens)\n",
        "3. The decode phase (generating new tokens)\n",
        "4. How KV cache accelerates the decode phase\n",
        "\n",
        "We'll use a simplified implementation to show the core concepts clearly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from typing import Optional, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple Decoder LLM Implementation\n",
        "\n",
        "We'll create a minimal decoder-only transformer to demonstrate the concepts. In practice, you'd use libraries like `transformers` or `vllm`, but this helps illustrate how KV cache works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class KVCache:\n",
        "    \"\"\"Simple KV cache storage\"\"\"\n",
        "    keys: torch.Tensor  # Shape: [batch_size, seq_len, num_heads, head_dim]\n",
        "    values: torch.Tensor  # Shape: [batch_size, seq_len, num_heads, head_dim]\n",
        "    \n",
        "    def append(self, new_keys: torch.Tensor, new_values: torch.Tensor):\n",
        "        \"\"\"Append new KV pairs to the cache\"\"\"\n",
        "        self.keys = torch.cat([self.keys, new_keys], dim=1)\n",
        "        self.values = torch.cat([self.values, new_values], dim=1)\n",
        "    \n",
        "    def get_cache_size(self):\n",
        "        \"\"\"Return the current sequence length in cache\"\"\"\n",
        "        return self.keys.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleAttention(nn.Module):\n",
        "    \"\"\"Simplified self-attention layer with KV cache support\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size: int, num_heads: int = 4):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_size // num_heads\n",
        "        \n",
        "        # Q, K, V projection matrices\n",
        "        self.q_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.k_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.v_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.o_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        kv_cache: Optional[KVCache] = None\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, hidden_size]\n",
        "            kv_cache: Optional KV cache from previous computations\n",
        "        \n",
        "        Returns:\n",
        "            output: Attention output [batch_size, seq_len, hidden_size]\n",
        "            all_keys: Keys for the full context [batch_size, total_seq_len, num_heads, head_dim]\n",
        "            all_values: Values for the full context [batch_size, total_seq_len, num_heads, head_dim]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        \n",
        "        # Compute Q, K, V\n",
        "        q = self.q_proj(x)\n",
        "        k = self.k_proj(x)\n",
        "        v = self.v_proj(x)\n",
        "        \n",
        "        # Reshape for multi-head attention\n",
        "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        \n",
        "        if kv_cache is not None:\n",
        "            cached_k = kv_cache.keys.transpose(1, 2)  # [batch, heads, cached_seq, head_dim]\n",
        "            cached_v = kv_cache.values.transpose(1, 2)\n",
        "            k_full = torch.cat([cached_k, k], dim=2)\n",
        "            v_full = torch.cat([cached_v, v], dim=2)\n",
        "        else:\n",
        "            k_full = k\n",
        "            v_full = v\n",
        "        \n",
        "        # Compute attention scores using the full context\n",
        "        scores = torch.matmul(q, k_full.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
        "        \n",
        "        # Apply causal mask (only attend to previous tokens)\n",
        "        if kv_cache is None:\n",
        "            mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(scores.device)\n",
        "            scores = scores.masked_fill(mask.unsqueeze(0).unsqueeze(0), float('-inf'))\n",
        "        \n",
        "        # Softmax\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        \n",
        "        # Apply attention to values from the full context\n",
        "        output = torch.matmul(attn_weights, v_full)  # [batch, heads, seq_len, head_dim]\n",
        "        \n",
        "        # Reshape and project\n",
        "        output = output.transpose(1, 2).contiguous()\n",
        "        output = output.view(batch_size, seq_len, self.hidden_size)\n",
        "        output = self.o_proj(output)\n",
        "        \n",
        "        all_keys = k_full.transpose(1, 2)   # [batch, total_seq_len, num_heads, head_dim]\n",
        "        all_values = v_full.transpose(1, 2)\n",
        "        \n",
        "        return output, all_keys, all_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"Single decoder block with attention and feed-forward\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size: int, num_heads: int = 4):\n",
        "        super().__init__()\n",
        "        self.attention = SimpleAttention(hidden_size, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.norm2 = nn.LayerNorm(hidden_size)\n",
        "        \n",
        "        # Simple feed-forward network\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size * 4, hidden_size)\n",
        "        )\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        kv_cache: Optional[KVCache] = None\n",
        "    ) -> Tuple[torch.Tensor, KVCache]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, hidden_size]\n",
        "            kv_cache: Optional KV cache\n",
        "        \n",
        "        Returns:\n",
        "            output: Block output\n",
        "            updated_cache: Updated KV cache for this layer\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        attn_out, all_keys, all_values = self.attention(self.norm1(x), kv_cache)\n",
        "        x = residual + attn_out\n",
        "        \n",
        "        residual = x\n",
        "        ffn_out = self.ffn(self.norm2(x))\n",
        "        x = residual + ffn_out\n",
        "        \n",
        "        if kv_cache is None:\n",
        "            updated_cache = KVCache(keys=all_keys, values=all_values)\n",
        "        else:\n",
        "            cached_len = kv_cache.get_cache_size()\n",
        "            new_keys = all_keys[:, cached_len:, :, :]\n",
        "            new_values = all_values[:, cached_len:, :, :]\n",
        "            if new_keys.shape[1] > 0:\n",
        "                kv_cache.append(new_keys, new_values)\n",
        "            updated_cache = kv_cache\n",
        "        \n",
        "        return x, updated_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleDecoderLLM(nn.Module):\n",
        "    \"\"\"Simple decoder-only language model\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int = 1000,\n",
        "        hidden_size: int = 128,\n",
        "        num_layers: int = 2,\n",
        "        num_heads: int = 4\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        # Token embeddings\n",
        "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        \n",
        "        # Decoder blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            DecoderBlock(hidden_size, num_heads) for _ in range(num_layers)\n",
        "        ])\n",
        "        \n",
        "        # Output projection\n",
        "        self.lm_head = nn.Linear(hidden_size, vocab_size)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        token_ids: torch.Tensor,\n",
        "        kv_caches: Optional[Dict[int, KVCache]] = None\n",
        "    ) -> Tuple[torch.Tensor, Dict[int, KVCache]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            token_ids: Input token IDs [batch_size, seq_len]\n",
        "            kv_caches: Optional dict of KV caches per layer\n",
        "        \n",
        "        Returns:\n",
        "            logits: Output logits [batch_size, seq_len, vocab_size]\n",
        "            new_kv_caches: Updated KV caches\n",
        "        \"\"\"\n",
        "        # Get embeddings\n",
        "        x = self.embedding(token_ids)\n",
        "        \n",
        "        # Process through decoder blocks\n",
        "        new_kv_caches = {}\n",
        "        for layer_idx, block in enumerate(self.blocks):\n",
        "            kv_cache = kv_caches.get(layer_idx) if kv_caches else None\n",
        "            x, updated_cache = block(x, kv_cache)\n",
        "            new_kv_caches[layer_idx] = updated_cache\n",
        "        \n",
        "        # Project to vocabulary\n",
        "        logits = self.lm_head(x)\n",
        "        \n",
        "        return logits, new_kv_caches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prefill Phase Demonstration\n",
        "\n",
        "The prefill phase processes the initial prompt tokens. All tokens are processed in parallel, and we compute the KV cache for all positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model created: 653,544 parameters\n",
            "Hidden size: 128, Layers: 2\n"
          ]
        }
      ],
      "source": [
        "# Create a simple model\n",
        "model = SimpleDecoderLLM(\n",
        "    vocab_size=1000,\n",
        "    hidden_size=128,\n",
        "    num_layers=2,\n",
        "    num_heads=4\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def clone_kv_caches(kv_dict: Dict[int, KVCache]) -> Dict[int, KVCache]:\n",
        "    \"\"\"Deep copy the KV caches so we can reuse the same prefill state.\"\"\"\n",
        "    return {\n",
        "        layer_idx: KVCache(keys=cache.keys.clone(), values=cache.values.clone())\n",
        "        for layer_idx, cache in kv_dict.items()\n",
        "    }\n",
        "\n",
        "print(f\"Model created: {count_parameters(model):,} parameters\")\n",
        "print(f\"Hidden size: {model.hidden_size}, Layers: {model.num_layers}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prefill Phase: Processing 5 prompt tokens\n",
            "Token IDs: [10, 20, 30, 40, 50]\n",
            "\n",
            "Processing all tokens in parallel...\n",
            "\n",
            "Prefill complete!\n",
            "Output logits shape: torch.Size([1, 5, 1000])\n",
            "KV cache created for 2 layers\n",
            "Each KV cache has sequence length: 5\n",
            "\n",
            "Layer 0 KV Cache:\n",
            "  Keys shape: torch.Size([1, 5, 4, 32])\n",
            "  Values shape: torch.Size([1, 5, 4, 32])\n",
            "\n",
            "Layer 1 KV Cache:\n",
            "  Keys shape: torch.Size([1, 5, 4, 32])\n",
            "  Values shape: torch.Size([1, 5, 4, 32])\n"
          ]
        }
      ],
      "source": [
        "# Simulate a prompt: \"Hello, my name is\"\n",
        "# In practice, you'd tokenize this with a real tokenizer\n",
        "prompt_tokens = torch.tensor([[10, 20, 30, 40, 50]])  # 5 tokens\n",
        "batch_size, prompt_len = prompt_tokens.shape\n",
        "\n",
        "print(f\"Prefill Phase: Processing {prompt_len} prompt tokens\")\n",
        "print(f\"Token IDs: {prompt_tokens.tolist()[0]}\")\n",
        "print(\"\\nProcessing all tokens in parallel...\")\n",
        "\n",
        "# Prefill: no KV cache initially\n",
        "with torch.no_grad():\n",
        "    logits, kv_caches = model(prompt_tokens, kv_caches=None)\n",
        "\n",
        "print(f\"\\nPrefill complete!\")\n",
        "print(f\"Output logits shape: {logits.shape}\")  # [batch, seq_len, vocab_size]\n",
        "print(f\"KV cache created for {len(kv_caches)} layers\")\n",
        "print(f\"Each KV cache has sequence length: {kv_caches[0].get_cache_size()}\")\n",
        "\n",
        "# Show the cache structure\n",
        "for layer_idx, cache in kv_caches.items():\n",
        "    print(f\"\\nLayer {layer_idx} KV Cache:\")\n",
        "    print(f\"  Keys shape: {cache.keys.shape}\")\n",
        "    print(f\"  Values shape: {cache.values.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decode Phase Demonstration\n",
        "\n",
        "The decode phase generates new tokens one at a time. We reuse the KV cache from prefill, so we only need to:\n",
        "1. Process the new token\n",
        "2. Append its KV cache to the existing cache\n",
        "\n",
        "This is much faster than recomputing attention over all previous tokens!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decode Phase: Generating tokens one at a time using KV cache\n",
            "============================================================\n",
            "Token 1 (from prefill logits): 988\n",
            "\n",
            "--- Decode Step 1 ---\n",
            "Input token ID: 988\n",
            "KV cache size before decode: 5\n",
            "Generated token ID: 254\n",
            "KV cache size after decode: 6\n",
            "\n",
            "Key insight: We only processed 1 token, but attention can see all 6 tokens!\n",
            "\n",
            "--- Decode Step 2 ---\n",
            "Input token ID: 254\n",
            "KV cache size before decode: 6\n",
            "Generated token ID: 767\n",
            "KV cache size after decode: 7\n",
            "\n",
            "Key insight: We only processed 1 token, but attention can see all 7 tokens!\n",
            "\n",
            "--- Decode Step 3 ---\n",
            "Input token ID: 767\n",
            "KV cache size before decode: 7\n",
            "Generated token ID: 487\n",
            "KV cache size after decode: 8\n",
            "\n",
            "Key insight: We only processed 1 token, but attention can see all 8 tokens!\n",
            "\n",
            "--- Decode Step 4 ---\n",
            "Input token ID: 487\n",
            "KV cache size before decode: 8\n",
            "Generated token ID: 930\n",
            "KV cache size after decode: 9\n",
            "\n",
            "Key insight: We only processed 1 token, but attention can see all 9 tokens!\n"
          ]
        }
      ],
      "source": [
        "def sample_token(logits: torch.Tensor) -> int:\n",
        "    \"\"\"Simple greedy sampling (take highest probability token)\"\"\"\n",
        "    last_token_logits = logits[0, -1, :]\n",
        "    token_id = torch.argmax(last_token_logits).item()\n",
        "    return token_id\n",
        "\n",
        "print(\"Decode Phase: Generating tokens one at a time using KV cache\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Work on a clone so we keep the prefill caches intact\n",
        "current_kv_caches = clone_kv_caches(kv_caches)\n",
        "generated_tokens: list[int] = []\n",
        "num_tokens_to_generate = 5\n",
        "\n",
        "if num_tokens_to_generate <= 0:\n",
        "    print(\"No tokens requested; skipping decode phase.\")\n",
        "else:\n",
        "    device = prompt_tokens.device\n",
        "    first_token = sample_token(logits)\n",
        "    generated_tokens.append(first_token)\n",
        "    print(f\"Token 1 (from prefill logits): {first_token}\")\n",
        "    current_token = torch.tensor([[first_token]], dtype=torch.long, device=device)\n",
        "    \n",
        "    for step in range(1, num_tokens_to_generate):\n",
        "        print(f\"\\n--- Decode Step {step} ---\")\n",
        "        print(f\"Input token ID: {current_token.item()}\")\n",
        "        print(f\"KV cache size before decode: {current_kv_caches[0].get_cache_size()}\")\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            step_logits, current_kv_caches = model(current_token, kv_caches=current_kv_caches)\n",
        "        \n",
        "        next_token = sample_token(step_logits)\n",
        "        generated_tokens.append(next_token)\n",
        "        \n",
        "        print(f\"Generated token ID: {next_token}\")\n",
        "        print(f\"KV cache size after decode: {current_kv_caches[0].get_cache_size()}\")\n",
        "        print(f\"\\nKey insight: We only processed 1 token, but attention can see all {current_kv_caches[0].get_cache_size()} tokens!\")\n",
        "        \n",
        "        current_token = torch.tensor([[next_token]], dtype=torch.long, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Summary of Prefill + Decode\n",
            "============================================================\n",
            "\n",
            "Prompt tokens: [10, 20, 30, 40, 50]\n",
            "Generated tokens (sampled): [988, 254, 767, 487, 930]\n",
            "\n",
            "Total sequence length in KV cache: 9\n",
            "  - Prompt: 5 tokens\n",
            "  - Generated cached: 4 tokens\n",
            "  - Generated sampled (including next-to-process): 5 tokens\n",
            "\n",
            "✅ KV cache successfully accumulated the processed tokens!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Summary of Prefill + Decode\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nPrompt tokens: {prompt_tokens.tolist()[0]}\")\n",
        "print(f\"Generated tokens (sampled): {generated_tokens}\")\n",
        "\n",
        "total_seq_len = current_kv_caches[0].get_cache_size()\n",
        "cached_generated = total_seq_len - prompt_len\n",
        "print(f\"\\nTotal sequence length in KV cache: {total_seq_len}\")\n",
        "print(f\"  - Prompt: {prompt_len} tokens\")\n",
        "print(f\"  - Generated cached: {cached_generated} tokens\")\n",
        "print(f\"  - Generated sampled (including next-to-process): {len(generated_tokens)} tokens\")\n",
        "print(f\"\\n✅ KV cache successfully accumulated the processed tokens!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Comparison: With vs Without KV Cache\n",
        "\n",
        "Let's demonstrate why KV cache is essential for efficient decoding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparing decode performance for 10 tokens...\n",
            "============================================================\n",
            "\n",
            "With KV Cache:    0.0055 seconds\n",
            "Without KV Cache: 0.0090 seconds\n",
            "\n",
            "Speedup: 1.63x faster with KV cache!\n",
            "\n",
            "Generated tokens (with cache): [988, 254, 767, 487, 930, 89, 698, 683, 711, 581]\n",
            "Generated tokens (without cache): [988, 254, 767, 487, 930, 89, 698, 683, 711, 581]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def decode_without_kv_cache(model, prompt_tokens, num_tokens):\n",
        "    \"\"\"Decode without KV cache (inefficient - recomputes everything)\"\"\"\n",
        "    generated = []\n",
        "    current_sequence = prompt_tokens.clone()\n",
        "    device = prompt_tokens.device\n",
        "    \n",
        "    for _ in range(num_tokens):\n",
        "        with torch.no_grad():\n",
        "            logits, _ = model(current_sequence, kv_caches=None)\n",
        "        next_token = sample_token(logits)\n",
        "        generated.append(next_token)\n",
        "        next_token_tensor = torch.tensor([[next_token]], dtype=torch.long, device=device)\n",
        "        current_sequence = torch.cat([current_sequence, next_token_tensor], dim=1)\n",
        "    \n",
        "    return generated\n",
        "\n",
        "def decode_with_kv_cache(model, prompt_tokens, kv_caches, prefill_logits, num_tokens):\n",
        "    \"\"\"Decode with KV cache (efficient)\"\"\"\n",
        "    generated = []\n",
        "    if num_tokens <= 0:\n",
        "        return generated\n",
        "    \n",
        "    current_kv_caches = clone_kv_caches(kv_caches)\n",
        "    device = prompt_tokens.device\n",
        "    \n",
        "    first_token = sample_token(prefill_logits)\n",
        "    generated.append(first_token)\n",
        "    current_token = torch.tensor([[first_token]], dtype=torch.long, device=device)\n",
        "    \n",
        "    for _ in range(num_tokens - 1):\n",
        "        with torch.no_grad():\n",
        "            logits, current_kv_caches = model(current_token, kv_caches=current_kv_caches)\n",
        "        next_token = sample_token(logits)\n",
        "        generated.append(next_token)\n",
        "        current_token = torch.tensor([[next_token]], dtype=torch.long, device=device)\n",
        "    \n",
        "    return generated\n",
        "\n",
        "# Compare performance\n",
        "num_decode_tokens = 10\n",
        "\n",
        "print(f\"Comparing decode performance for {num_decode_tokens} tokens...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# With KV cache\n",
        "start_time = time.time()\n",
        "generated_with_cache = decode_with_kv_cache(model, prompt_tokens, kv_caches, logits, num_decode_tokens)\n",
        "time_with_cache = time.time() - start_time\n",
        "\n",
        "# Without KV cache (recompute everything)\n",
        "start_time = time.time()\n",
        "generated_without_cache = decode_without_kv_cache(model, prompt_tokens, num_decode_tokens)\n",
        "time_without_cache = time.time() - start_time\n",
        "\n",
        "print(f\"\\nWith KV Cache:    {time_with_cache:.4f} seconds\")\n",
        "print(f\"Without KV Cache: {time_without_cache:.4f} seconds\")\n",
        "print(f\"\\nSpeedup: {time_without_cache / time_with_cache:.2f}x faster with KV cache!\")\n",
        "print(f\"\\nGenerated tokens (with cache): {generated_with_cache}\")\n",
        "print(f\"Generated tokens (without cache): {generated_without_cache}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization: How KV Cache Works\n",
        "\n",
        "Let's visualize the attention patterns to see how KV cache helps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prefill Phase Attention Pattern:\n",
            "All tokens attend to all previous tokens\n",
            "\n",
            "Decode Phase Attention Pattern:\n",
            "Each new token attends to all cached tokens\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Key insight: In decode phase, each step only processes 1 token,\n",
            "but can attend to all 10 cached tokens!\n"
          ]
        }
      ],
      "source": [
        "def visualize_attention_pattern(model, prompt_tokens, num_decode_steps=3):\n",
        "    \"\"\"Visualize attention patterns during prefill and decode\"\"\"\n",
        "    \n",
        "    # Prefill phase\n",
        "    print(\"Prefill Phase Attention Pattern:\")\n",
        "    print(\"All tokens attend to all previous tokens\")\n",
        "    prefill_len = prompt_tokens.shape[1]\n",
        "    \n",
        "    # Create attention matrix for prefill (causal mask)\n",
        "    prefill_attention = torch.tril(torch.ones(prefill_len, prefill_len))\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(prefill_attention.numpy(), cmap='Blues', aspect='auto')\n",
        "    plt.title(f'Prefill Phase: {prefill_len} tokens processed in parallel')\n",
        "    plt.xlabel('Key Position')\n",
        "    plt.ylabel('Query Position')\n",
        "    plt.colorbar()\n",
        "    \n",
        "    # Decode phase\n",
        "    print(\"\\nDecode Phase Attention Pattern:\")\n",
        "    print(\"Each new token attends to all cached tokens\")\n",
        "    \n",
        "    # Simulate decode steps\n",
        "    decode_attention = []\n",
        "    current_kv_caches = None\n",
        "    \n",
        "    # Get prefill KV cache\n",
        "    with torch.no_grad():\n",
        "        _, current_kv_caches = model(prompt_tokens, kv_caches=None)\n",
        "    \n",
        "    generated_tokens = []\n",
        "    current_token = prompt_tokens[:, -1:]\n",
        "    \n",
        "    for step in range(num_decode_steps):\n",
        "        if step > 0:\n",
        "            current_token = torch.tensor([[generated_tokens[step-1]]])\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            logits, current_kv_caches = model(current_token, kv_caches=current_kv_caches)\n",
        "        \n",
        "        # Each decode step: 1 query attends to all cached keys\n",
        "        cache_size = current_kv_caches[0].get_cache_size()\n",
        "        attention_row = torch.ones(cache_size)\n",
        "        decode_attention.append(attention_row.numpy())\n",
        "        \n",
        "        # Sample token for next iteration\n",
        "        if step < num_decode_steps - 1:\n",
        "            next_token = sample_token(logits)\n",
        "            generated_tokens.append(next_token)\n",
        "    \n",
        "    # Pad for visualization\n",
        "    max_len = max(len(row) for row in decode_attention)\n",
        "    decode_matrix = np.array([np.pad(row, (0, max_len - len(row))) for row in decode_attention])\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(decode_matrix, cmap='Greens', aspect='auto')\n",
        "    plt.title(f'Decode Phase: {num_decode_steps} tokens generated sequentially')\n",
        "    plt.xlabel('Key Position (cached)')\n",
        "    plt.ylabel('Decode Step')\n",
        "    plt.colorbar()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nKey insight: In decode phase, each step only processes 1 token,\")\n",
        "    print(f\"but can attend to all {current_kv_caches[0].get_cache_size()} cached tokens!\")\n",
        "\n",
        "visualize_attention_pattern(model, prompt_tokens, num_decode_steps=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts Summary\n",
        "\n",
        "### Prefill Phase:\n",
        "- Processes all prompt tokens **in parallel**\n",
        "- Computes KV cache for all prompt positions\n",
        "- Time complexity: O(n²) for n prompt tokens\n",
        "- Example: Processing \"Hello, my name is\" (5 tokens) all at once\n",
        "\n",
        "### Decode Phase:\n",
        "- Generates tokens **one at a time**\n",
        "- Reuses KV cache from prefill + previous decode steps\n",
        "- Only processes the new token, but can attend to all cached tokens\n",
        "- Time complexity: O(k) per token where k is cached sequence length\n",
        "- Example: Generating \"Isaac\" token by token (4 tokens, one at a time)\n",
        "\n",
        "### Why KV Cache Matters:\n",
        "- **Without KV cache**: Each decode step reprocesses all previous tokens → O(n²) per token\n",
        "- **With KV cache**: Each decode step only processes 1 token → O(n) per token\n",
        "- This makes decoding **much faster** for long sequences!\n",
        "\n",
        "### Real-World Usage:\n",
        "- Libraries like `vLLM` and `transformers` implement KV cache automatically\n",
        "- The cache can be shared across multiple requests (prefix caching)\n",
        "- The cache can be transferred between devices (disaggregated inference)\n",
        "- The cache can be quantized to save memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "To see KV cache in action with real models:\n",
        "- Check out `basic_offline_inference.py` for vLLM usage\n",
        "- Check out `disaggregated_prefill_decode.py` for KV cache transfer\n",
        "- Check out `prefix_caching.py` for shared KV cache across requests\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
